{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 516,
      "metadata": {
        "id": "Oke67ZoPHcqQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "Mx-h8wu0UdLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the train and test datasets\n",
        "df_train = pd.read_csv('/content/adult.data', header=None)\n",
        "df_test = pd.read_csv('/content/adult.test', skiprows=[0], header=None)"
      ],
      "metadata": {
        "id": "qMINMyBzISb3"
      },
      "execution_count": 517,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "    # Remove extra spaces in the object features\n",
        "    df[df.select_dtypes(include=['object']).columns] = df[df.select_dtypes(include=['object']).columns].apply(lambda col: col.map(str.strip))\n",
        "\n",
        "    # Replace missing values, indicated with '?' in the dataset with Nan\n",
        "    df.replace('?', pd.NA, inplace=True)\n",
        "\n",
        "    # Fill the columns with missing values with the Mode as they are categorical values\n",
        "    df[[1, 6, 13]] = df[[1, 6, 13]].apply(lambda col: col.fillna(col.mode()[0]))\n",
        "\n",
        "    # Convert categorical to numerical values\n",
        "    df = pd.get_dummies(df, columns=[1, 3, 5, 6, 7, 8, 9, 13], drop_first=True)\n",
        "\n",
        "    # Convert target values to 0 and 1\n",
        "    df[14] = df[14].apply(lambda x: 1 if '>50K' in x else 0)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "GTjJrzAtZ84I"
      },
      "execution_count": 518,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = clean_data(df_train)\n",
        "df_test = clean_data(df_test)"
      ],
      "metadata": {
        "id": "r8o5K2YuZ_oH"
      },
      "execution_count": 519,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reindex test set to have the same columns as the train set\n",
        "df_test = df_test.reindex(columns=df_train.columns, fill_value=False)  # Fill the missing column with False\n",
        "\n",
        "# Split training and testing sets\n",
        "X_train = df_train.drop(14, axis=1)\n",
        "y_train = df_train[14]\n",
        "X_test = df_test.drop(14, axis=1)\n",
        "y_test = df_test[14]\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.values)\n",
        "X_test = scaler.transform(X_test.values)"
      ],
      "metadata": {
        "id": "9p6FTZsMb07I"
      },
      "execution_count": 520,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "# Handle the shapes\n",
        "y_train = y_train.unsqueeze(1)\n",
        "y_test = y_test.unsqueeze(1)"
      ],
      "metadata": {
        "id": "zstoVlOJOkeQ"
      },
      "execution_count": 521,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model"
      ],
      "metadata": {
        "id": "bCCkYtHDNvJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model structure\n",
        "class IncomeClassifier(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define layers\n",
        "        self.layer1 = nn.Linear(input_size, 64)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.output = nn.Linear(32, 1)\n",
        "\n",
        "        # Define activation function\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.output(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jZrlLDtYqgBM"
      },
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiating the model\n",
        "input_size = 97\n",
        "model = IncomeClassifier(input_size)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Create a dataset from the tensors\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "\n",
        "# Create a DataLoader for mini-batch training\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "z5maq82RvQNX"
      },
      "execution_count": 523,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_train_loss = 0.0\n",
        "\n",
        "    # Zero the gradients before each update\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        # Forward pass: Get predictions from the model\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate the average loss of this epoch\n",
        "        running_train_loss += loss.item()\n",
        "\n",
        "    # Compute average training loss for the epoch\n",
        "    avg_train_loss = running_train_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Compute the validation loss\n",
        "        val_outputs = model(X_test)\n",
        "        val_loss = loss_fn(val_outputs, y_test)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbA-swBcPUFe",
        "outputId": "0542eeae-7557-4171-cf15-451ab08507bb"
      },
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Training Loss: 0.4702, Validation Loss: 0.3781\n",
            "Epoch [2/10], Training Loss: 0.3515, Validation Loss: 0.3494\n",
            "Epoch [3/10], Training Loss: 0.3366, Validation Loss: 0.3450\n",
            "Epoch [4/10], Training Loss: 0.3279, Validation Loss: 0.3401\n",
            "Epoch [5/10], Training Loss: 0.3233, Validation Loss: 0.3375\n",
            "Epoch [6/10], Training Loss: 0.3190, Validation Loss: 0.3381\n",
            "Epoch [7/10], Training Loss: 0.3186, Validation Loss: 0.3450\n",
            "Epoch [8/10], Training Loss: 0.3182, Validation Loss: 0.3424\n",
            "Epoch [9/10], Training Loss: 0.3168, Validation Loss: 0.3368\n",
            "Epoch [10/10], Training Loss: 0.3086, Validation Loss: 0.3342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables for tracking accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Forward pass for the test data\n",
        "    val_outputs = model(X_test)\n",
        "\n",
        "    # Apply sigmoid to convert logits to probabilities\n",
        "    probabilities = torch.sigmoid(val_outputs)\n",
        "\n",
        "    # 0.5 threshold for binary classification\n",
        "    predicted = (probabilities > 0.5).float()\n",
        "\n",
        "    # Calculate the number of correct predictions\n",
        "    correct = (predicted == y_test).sum().item()\n",
        "    total = y_test.size(0)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct / total\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH5QU8yfIYRs",
        "outputId": "47ce6228-be1a-4be9-ed0f-59c20d84866f"
      },
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.72%\n"
          ]
        }
      ]
    }
  ]
}